---
title: "Using the CCEB High Performance Computing Cluster: Terminology and Specifications"
author: "Alessandra Valcarcel"
date: 2019-04-27T21:01:01-06:00
categories: ["Computing"]
tags: ["Cluster", "CCEB", "LSF", "IBM"]
output: 
  bookdown::html_document2:
    number_sections: false
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(out.width = '80%',
                      fig.align = 'center', 
                      echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE)
```

# Introduction

This is the fourth blog post in a series of articles about using the CCEB cluster. An overview of the series is available [here](www.alessandravalcarcel.com/blog/2019-04-13-clusterintro/). This post focuses on the general terminology surrounding high performance computing clusters and an overview of the CCEB cluster specifications.

Most of the information presented in this article was taken from IBM resources [here](https://www.ibm.com/support/knowledgecenter/en/SSETD4_9.1.2/lsf_foundations/lsf_introduction_to.html) and Microsoft [here](https://blogs.technet.microsoft.com/windowshpc/2008/04/14/how-that-nodesocketcore-thing-works/). You should explore these sites on your own for specific details.

# Cluster Versus Grid

__Cluster computing__ uses several nodes that are made to run as a single entity. These nodes are connected by a local area network (LAN). A cluster is homogeneous in that they have all the same hardware and operating systems.

__Grid computing__ is the segregation of resources across multiple sites. Grids are are heterogeneous. The computers that are part of a grid can run different operating systems, have different hardware, and be in different geographical locations.

__Cloud computing__ is a new computing paradigm which provides a large pool of dynamic, scalable, and virtual resources to run processes. Think [Amazon Web Services](https://aws.amazon.com/).

__Grid computing__ is sometimes distinguished from conventional high-performance computing systems such as __cluster computing__ in that grid computers have each node set to perform a different task/application or may have clusters in different geographical locations. A grid is a cluster but a cluster is not necessarily a grid.

Our CCEB resources were previously housed in different buildings meeting the spatial definition of a grid, but they were recently all moved into the same location. The operating system is the same across the entire machine but different machines are able to run different software programs (i.e. SAS, MATLAB, R). Technically, I believe the CCEB high performance computing resources are categorized as __grid computing__. Personally, I use cluster to reference the machine though. Others use grid. To be honest, for our purposes, the language of how we speak of the CCEB High Performance Computing (HPC) resources doesn't matter. Both won't affect how effectively we Google questions or discuss the resources among ourselves.

If you want to read more, this content was mostly taken from a really nice article in the International Journal of Advanced Research in Computer and Communication Engineering and [Wikipedia](https://www.wikipedia.org/). The links are provided below: 

- [Grid Definitions on Wikipedia](https://en.wikipedia.org/wiki/Grid_computing)
- [Cluster Definitions on Wikipedia](https://en.wikipedia.org/wiki/Computer_cluster)
- [Article discussing the subtle differences between Cloud Computing, Grid Computing, and Cluster Computing](https://pdfs.semanticscholar.org/5e6e/9b4b7f4d986bc9f1246198c50c8d43d2d695.pdf). 

# Hosts

https://www.ibm.com/support/knowledgecenter/en/SSETD4_9.1.3/lsf_users_guide/hosts_about.html

Hosts on the cluster perform different functions.

- __Master host__: A server host acts as the overall coordinator for the cluster, doing all job scheduling and dispatch.

- __Server host__: A host that submits and runs jobs.

- __Client host__: A host that only submits jobs and tasks.

- __Execution host__: A host that runs jobs and tasks.

- __Submission host__: A host from which jobs and tasks are submitted.

Typically, we only interact with __server__, __client__, __execution__, and __submission__ hosts. The __master__ host is working in the background after we submit jobs. In our department, we most commonly refer to all of these generically as __host__ and don't clarify which type of __host__. It can get confusing so for this document I'll try to always clarify.

If you simply `ssh` onto the CCEB cluster you are put onto a __submission host__. No jobs can be run on this host directly but are submit and sent to run on other __execution hosts__. If you are part of a different queue, for example Taki or [PennSIVE's](https://www.med.upenn.edu/pennsive/personnel.html) group, then they use a __server host__, takim, so when you `ssh` onto the cluster your jobs are submit from there but can also be run on content on takim. Once you submit a job from these hosts, you tasks are run on __execution hosts__.  

### Nodes, Sockets, and Cores

A __node__ (a.k.a. host, machine, computer) refers to an entire compute node.  Each node contains 1 or more sockets. Notice, this is synonymous with host/machine.

A __socket__ (a.k.a. numa node) refers to collection of cores with a direct pipe to memory.  Each socket contains 1 or more cores.  Note that this does not necessarily refer to a physical socket, but rather to the memory architecture of the machine, which will depend on your chip vendor. I pretty much never think about this level or use this language.

A __core__ (a.k.a. processor, cpu, cpu core, logical processor) refers to a single processing unit capable of performing computations. A __core__ is the smallest unit of allocation available in high performance computing.

When you `bsub` an interactive session with 1 core requested by definition you are using 1 core on 1 node or host. When you submit a normal job you can request multiple cores and unless specified they may be across multiple hosts/machines.

## Job

A __job__ is the unit of work (i.e. your code) that is running on the cluster. A __job__ is submit using a command. The __master host__ schedules, controls, and tracks the job according to configured policies. __Jobs__ can be complex problems, simulation scenarios, extensive calculations, or anything that needs compute power.

This language often gets confusing because we refer to the entire thing running as a batch or array job (i.e. all 1000 of your simulations running) and we refer to each 1000 iterations as single jobs. If you ever get confused just ask for clarification.

When you submit a __job__ it goes into a __job slot__ or a bucket from which a single unit of work is assigned on the grid system. Hosts can be configured with multiple __job slots__ and you can dispatch jobs from queues until all the __job slots__ are filled. You can correlate __job slots__ with the total number of CPUs in the cluster.

Each job is assigned a number. You can use this number to check on the memory of your job, kill or stop your job, or include when emailing issues to PMACs.

## Queue

A __queue__ is a cluster-wide container for jobs. All jobs wait in queues until they are scheduled and dispatched to hosts. __Queues__ do not correspond to individual hosts; each queue can use all __server hosts__ on the cluster, or a configured subset of the __server hosts__. When you submit a job to a __queue__, you do not need to specify an __execution host__. The __master host__ dispatches the job to the best available __execution host__ on the cluster to run that job. You can specify an __execution host__ if you want but this is only useful for quality control.

Queues implement different job scheduling and control policies.

## "Layout"

```{r clusthardware, echo = FALSE, out.width = "100%", fig.cap = c("Pictoral representation of the hardware and layout of the grid. This graphic is not the accurate physical layout but simply provided as an example.")}
knitr::include_graphics('img/terminology/cluster_hardware.png')
```

- The __submission host__ also has nodes but cannot compute on this host. A __server host__ can also be used to submit jobs but it is not a good idea to use this for running code. Imagine if a __server host__ crashed then all dependent __execute hosts__ would crash and everyone running jobs in your queue would be very angry. 

The machine that you are put on after `ssh`-ing with `ssh pennkey@scisub` is simply a __submission host__. You are not permitted to run any processes on this host but rather have to `bsub` onto another machine. On the other hand, Taki's queue puts you onto a __server host__. This host can both submit jobs and also run jobs. We can compute on takim but it is dangerous. 

We will talk about the `bsub` command in the next few blog posts but this will be how you get onto an execute host to actually run code and jobs.

# PMACS High Performance Computing (HPC) Grids {#cluster-specs}

These specifications were true as of April 22, 2019. The internal wiki for up to date information can be found [here](https://dbe.med.upenn.edu/secure/wiki/index.php?title=Linux_Grid_Help).

PMACS Limited Performance Computing (LPC) cluster is a new grid (IBM Spectrum) and the cluster is comprised a variety of hosts running CentOS Linux. Currently, two Linux hosting servers are available to submit jobs to Grid and/or run applications in an Interactive session. The CCEB HPC Statistical Grid has been run and supported over the past 15+ years by PMACS. The CCEB HPC is an LSF ("LSF", short for load sharing facility) software. LSF is an [IBM platform](https://www.ibm.com/support/knowledgecenter/en/SSETD4/product_welcome_platform_lsf.html).

- This is industry-leading enterprise-class software that distributes work across existing heterogeneous IT resources to create a shared, scalable, and fault-tolerant infrastructure, that delivers faster, more reliable workload performance and reduces cost.

- LSF balances load, allocates resources, and provides access to those resources.

This Statistical HPC is composed of 144 Matlab cores, 80 SAS cores, 144 Stata cores, and 524 unrestricted R). More information about machine specification and memory is available through the [Wiki](https://dbe.med.upenn.edu/secure/wiki/index.php?title=Linux_Grid_Help).

The current setup defaults to assigning one core for each job submitted to the HPC Grid, although proper set-up and usage of Matlab pools and R parallel packages will allow up to 12 cores to be used concurrently for a job.

Any one user may only use up to 50 cores (e.g., 50 1-core jobs) running concurrently on the grid.
